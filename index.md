---
layout: page
---

<div class="aside">
<h1>Browse QA-SRL + QANom</h1>
<p class="leadText">
    QA-SRL with nominalizations on 8,000 sentences.
</p>
<a href="http://browse.qasrl.org" role="button" style = "padding: 8px; background-color: #dd4444; color: white; font-weight: bold;">
    Explore the data Â»
</a>
</div>

## About the QA-SRL Project

We are a group of researchers spanning
the [University of Washington](https://www.cs.washington.edu/),
[Bar-Ilan University](http://cs.biu.ac.il//en/),
[Facebook AI Research](https://research.fb.com/category/facebook-ai-research/), and the
[Allen Institute for Artificial Intelligence](https://allenai.org/).
Our goal is to advance the state of the art in broad-coverage natural language understanding.
We believe the way forward is with new datasets that are:

- **Crowdsourced**: modern machine learning methods require big training sets, which means scalability is a top priority.
- **Richly structured**: in order to improve over powerful representations learned from unlabeled data, we need strong, structured supervision signal.
- **Extensible**: annotation schemas should be flexible enough to accommodate new semantic phenomena without requiring expensive rounds of reannotation or brittle postprocessing rules.

Our [research](#publications) explores a variety of points in the design space spanned by these criteria. The common feature between our projects is **using natural language to annotate natural language**. This results in interpretable structures that can be annotated by non-experts at scale, which have the further advantage of being agnostic to choices of linguistic formalism.
